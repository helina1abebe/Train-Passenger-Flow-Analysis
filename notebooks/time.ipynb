{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5a6739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "563f36bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/EW-time table for Upward.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "083bf861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Stations ', 'Stations -code', 'Train times', '10102', '10202', '10302',\n",
       "       '10402', '10502', '10602', '10702', '10802', '10104', '10204', '10304',\n",
       "       '10404', '10504', '10604', '10704', '10804', '10106', '10206', '10306',\n",
       "       '10406', '10506', '10606', '10706', '10806', '10108', '10208', '10308',\n",
       "       '10408', '10508', '10608', '10708', '10808', '10110', '10210', '10310',\n",
       "       '10410', '10510', '10610', '10710', '10810', '10112', '10212', '10312',\n",
       "       '10412', '10512', '10612', '10712', '10812', '10114', '10214', '10314',\n",
       "       '10414', '10514', '10614', '10714', '10814', '10116', '10216', '10316',\n",
       "       '10516', '10616', '10716', '10118', '10218', '10318', '10518'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bbde86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stations</th>\n",
       "      <th>Stations -code</th>\n",
       "      <th>Train times</th>\n",
       "      <th>10102</th>\n",
       "      <th>10202</th>\n",
       "      <th>10302</th>\n",
       "      <th>10402</th>\n",
       "      <th>10502</th>\n",
       "      <th>10602</th>\n",
       "      <th>10702</th>\n",
       "      <th>...</th>\n",
       "      <th>10116</th>\n",
       "      <th>10216</th>\n",
       "      <th>10316</th>\n",
       "      <th>10516</th>\n",
       "      <th>10616</th>\n",
       "      <th>10716</th>\n",
       "      <th>10118</th>\n",
       "      <th>10218</th>\n",
       "      <th>10318</th>\n",
       "      <th>10518</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Torhailoch T12202</td>\n",
       "      <td>EW22</td>\n",
       "      <td>Returning</td>\n",
       "      <td>5:55:39</td>\n",
       "      <td>6:09:39</td>\n",
       "      <td>6:20:39</td>\n",
       "      <td>6:32:11</td>\n",
       "      <td>6:46:46</td>\n",
       "      <td>7:01:46</td>\n",
       "      <td>7:16:46</td>\n",
       "      <td>...</td>\n",
       "      <td>19:46:46</td>\n",
       "      <td>20:01:46</td>\n",
       "      <td>20:16:46</td>\n",
       "      <td>20:31:46</td>\n",
       "      <td>20:46:46</td>\n",
       "      <td>21:01:46</td>\n",
       "      <td>21:16:46</td>\n",
       "      <td>21:31:46</td>\n",
       "      <td>21:46:46</td>\n",
       "      <td>22:01:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Torhailoch T12201</td>\n",
       "      <td>EW22</td>\n",
       "      <td>Returning</td>\n",
       "      <td>6:55:39</td>\n",
       "      <td>7:09:39</td>\n",
       "      <td>7:20:39</td>\n",
       "      <td>7:32:11</td>\n",
       "      <td>7:09:39</td>\n",
       "      <td>7:20:39</td>\n",
       "      <td>7:32:11</td>\n",
       "      <td>...</td>\n",
       "      <td>19:46:41</td>\n",
       "      <td>20:01:41</td>\n",
       "      <td>20:21:41</td>\n",
       "      <td>20:41:41</td>\n",
       "      <td>21:01:41</td>\n",
       "      <td>21:21:41</td>\n",
       "      <td>21:41:41</td>\n",
       "      <td>22:01:41</td>\n",
       "      <td>22:21:41</td>\n",
       "      <td>22:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cocacola</td>\n",
       "      <td>EW21</td>\n",
       "      <td>Departure</td>\n",
       "      <td>7:55:39</td>\n",
       "      <td>8:09:39</td>\n",
       "      <td>8:20:39</td>\n",
       "      <td>8:32:11</td>\n",
       "      <td>6:44:59</td>\n",
       "      <td>6:59:59</td>\n",
       "      <td>7:14:59</td>\n",
       "      <td>...</td>\n",
       "      <td>19:44:59</td>\n",
       "      <td>19:59:59</td>\n",
       "      <td>20:19:59</td>\n",
       "      <td>20:39:59</td>\n",
       "      <td>20:59:59</td>\n",
       "      <td>21:19:59</td>\n",
       "      <td>21:39:59</td>\n",
       "      <td>21:59:59</td>\n",
       "      <td>22:19:59</td>\n",
       "      <td>22:42:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Stations  Stations -code Train times    10102    10202    10302  \\\n",
       "0  Torhailoch T12202           EW22  Returning   5:55:39  6:09:39  6:20:39   \n",
       "1  Torhailoch T12201           EW22  Returning   6:55:39  7:09:39  7:20:39   \n",
       "2           Cocacola           EW21   Departure  7:55:39  8:09:39  8:20:39   \n",
       "\n",
       "     10402    10502    10602    10702  ...     10116     10216     10316  \\\n",
       "0  6:32:11  6:46:46  7:01:46  7:16:46  ...  19:46:46  20:01:46  20:16:46   \n",
       "1  7:32:11  7:09:39  7:20:39  7:32:11  ...  19:46:41  20:01:41  20:21:41   \n",
       "2  8:32:11  6:44:59  6:59:59  7:14:59  ...  19:44:59  19:59:59  20:19:59   \n",
       "\n",
       "      10516     10616     10716     10118     10218     10318     10518  \n",
       "0  20:31:46  20:46:46  21:01:46  21:16:46  21:31:46  21:46:46  22:01:46  \n",
       "1  20:41:41  21:01:41  21:21:41  21:41:41  22:01:41  22:21:41  22:44:41  \n",
       "2  20:39:59  20:59:59  21:19:59  21:39:59  21:59:59  22:19:59  22:42:59  \n",
       "\n",
       "[3 rows x 69 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de0442b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.9  # 50%\n",
    "nan_cols = df.columns[df.isna().mean() > threshold]\n",
    "print(nan_cols)\n",
    "#drop nan_cols\n",
    "df = df.drop(columns=nan_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "460a4a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raname columns for better readability\n",
    "df = df.rename(columns={'Stations -code': 'station_id'})\n",
    "df = df.rename(columns={'Train times': 'arrival_departure'})\n",
    "df = df.rename(columns={'Stations ': 'Stations'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73c26047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrival_departure     Stations station_id train_id              Arrive  \\\n",
      "0                  Ayat T10136        EW1    10102 2025-07-24 05:17:28   \n",
      "1                  Ayat T10136        EW1    10104 2025-07-24 07:00:36   \n",
      "2                  Ayat T10136        EW1    10106 2025-07-24 09:00:36   \n",
      "3                  Ayat T10136        EW1    10108 2025-07-24 11:00:36   \n",
      "4                  Ayat T10136        EW1    10110 2025-07-24 13:00:36   \n",
      "\n",
      "arrival_departure Departure Outbound Returning            Departure  \n",
      "0                   5:20:28      NaN        NaN 2025-07-24 05:20:28  \n",
      "1                   7:02:00      NaN        NaN 2025-07-24 07:02:00  \n",
      "2                   9:02:00      NaN        NaN 2025-07-24 09:02:00  \n",
      "3                  11:02:00      NaN        NaN 2025-07-24 11:02:00  \n",
      "4                  13:02:00      NaN        NaN 2025-07-24 13:02:00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nebiy\\AppData\\Local\\Temp\\ipykernel_16124\\4248649633.py:23: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_pivot['Arrive'] = pd.to_datetime(df_pivot['Arrive'], errors='coerce')\n",
      "C:\\Users\\nebiy\\AppData\\Local\\Temp\\ipykernel_16124\\4248649633.py:24: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_pivot['Departure '] = pd.to_datetime(df_pivot['Departure'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "\n",
    "# Step 1: Add Arrival/Departure column based on row order\n",
    "df['arr_dep'] = ['Arrival' if i % 2 == 0 else 'Departure' for i in range(len(df))]\n",
    "\n",
    "# Step 2: Melt train columns\n",
    "id_vars = ['Stations', 'station_id', 'arrival_departure']\n",
    "value_vars = [col for col in df.columns if col not in id_vars]\n",
    "df_melted = df.melt(id_vars=id_vars, value_vars=value_vars,\n",
    "                    var_name='train_id', value_name='time')\n",
    "\n",
    "# Step 3: Pivot so we have Arrival & Departure per station/train\n",
    "df_pivot = df_melted.pivot_table(\n",
    "    index=['Stations', 'station_id', 'train_id'],\n",
    "    columns='arrival_departure',\n",
    "    values='time',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "# Optional: parse time column to datetime\n",
    "df_pivot['Arrive'] = pd.to_datetime(df_pivot['Arrive'], errors='coerce')\n",
    "df_pivot['Departure '] = pd.to_datetime(df_pivot['Departure'], errors='coerce')\n",
    "df_pivot= df_pivot.rename(columns={'Departure ': 'Departure'})\n",
    "\n",
    "# Done\n",
    "print(df_pivot.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb191cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Stations', 'station_id', 'train_id', 'Arrive', 'Departure', 'Outbound',\n",
       "       'Returning ', 'Departure'],\n",
       "      dtype='object', name='arrival_departure')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d3b4fce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_pivot[\u001b[33m'\u001b[39m\u001b[33mDwell_Time\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf_pivot\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDeparture\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_pivot\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mArrive\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nebiy\\Documents\\code\\Train-Passenger-Flow-Analysis\\venv\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nebiy\\Documents\\code\\Train-Passenger-Flow-Analysis\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:194\u001b[39m, in \u001b[36mOpsMixin.__sub__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__sub__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nebiy\\Documents\\code\\Train-Passenger-Flow-Analysis\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:7917\u001b[39m, in \u001b[36mDataFrame._arith_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   7914\u001b[39m axis: Literal[\u001b[32m1\u001b[39m] = \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# only relevant for Series other case\u001b[39;00m\n\u001b[32m   7915\u001b[39m other = ops.maybe_prepare_scalar_for_op(other, (\u001b[38;5;28mself\u001b[39m.shape[axis],))\n\u001b[32m-> \u001b[39m\u001b[32m7917\u001b[39m \u001b[38;5;28mself\u001b[39m, other = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_align_for_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   7919\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(\u001b[38;5;28mall\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   7920\u001b[39m     new_data = \u001b[38;5;28mself\u001b[39m._dispatch_frame_op(other, op, axis=axis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nebiy\\Documents\\code\\Train-Passenger-Flow-Analysis\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:8218\u001b[39m, in \u001b[36mDataFrame._align_for_op\u001b[39m\u001b[34m(self, other, axis, flex, level)\u001b[39m\n\u001b[32m   8211\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m left.axes[axis].equals(right.index):\n\u001b[32m   8212\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   8213\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mOperands are not aligned. Do \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   8214\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m`left, right = left.align(right, axis=1, copy=False)` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   8215\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mbefore operating.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   8216\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m8218\u001b[39m     left, right = \u001b[43mleft\u001b[49m\u001b[43m.\u001b[49m\u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   8219\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   8220\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mouter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   8221\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   8222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   8223\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   8224\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   8225\u001b[39m     right = left._maybe_align_series_as_frame(right, axis)\n\u001b[32m   8227\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m left, right\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nebiy\\Documents\\code\\Train-Passenger-Flow-Analysis\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:10466\u001b[39m, in \u001b[36mNDFrame.align\u001b[39m\u001b[34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[39m\n\u001b[32m  10453\u001b[39m     left, _right, join_index = \u001b[38;5;28mself\u001b[39m._align_frame(\n\u001b[32m  10454\u001b[39m         other,\n\u001b[32m  10455\u001b[39m         join=join,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10462\u001b[39m         fill_axis=fill_axis,\n\u001b[32m  10463\u001b[39m     )\n\u001b[32m  10465\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, ABCSeries):\n\u001b[32m> \u001b[39m\u001b[32m10466\u001b[39m     left, _right, join_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_align_series\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  10467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10469\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10473\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10474\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10475\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfill_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10476\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  10477\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m  10478\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33munsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(other)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nebiy\\Documents\\code\\Train-Passenger-Flow-Analysis\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:10609\u001b[39m, in \u001b[36mNDFrame._align_series\u001b[39m\u001b[34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis)\u001b[39m\n\u001b[32m  10607\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lidx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m  10608\u001b[39m     bm_axis = \u001b[38;5;28mself\u001b[39m._get_block_manager_axis(\u001b[32m1\u001b[39m)\n\u001b[32m> \u001b[39m\u001b[32m10609\u001b[39m     fdata = \u001b[43mfdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlidx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbm_axis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  10611\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m fdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mgr:\n\u001b[32m  10612\u001b[39m     fdata = fdata.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nebiy\\Documents\\code\\Train-Passenger-Flow-Analysis\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:674\u001b[39m, in \u001b[36mBaseBlockManager.reindex_indexer\u001b[39m\u001b[34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[39m\n\u001b[32m    672\u001b[39m \u001b[38;5;66;03m# some axes don't allow reindexing with dups\u001b[39;00m\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dups:\n\u001b[32m--> \u001b[39m\u001b[32m674\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_validate_can_reindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis >= \u001b[38;5;28mself\u001b[39m.ndim:\n\u001b[32m    677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mRequested axis not found in manager\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nebiy\\Documents\\code\\Train-Passenger-Flow-Analysis\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4328\u001b[39m, in \u001b[36mIndex._validate_can_reindex\u001b[39m\u001b[34m(self, indexer)\u001b[39m\n\u001b[32m   4326\u001b[39m \u001b[38;5;66;03m# trying to reindex on an axis with duplicates\u001b[39;00m\n\u001b[32m   4327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._index_as_unique \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m4328\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "df_pivot['Dwell_Time'] = df_pivot['Departure'] - df_pivot['Arrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3a0ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot.sort_values(by=['Dwell_Time', 'Arrival'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3993f994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>arrival_departure</th>\n",
       "      <th>Stations</th>\n",
       "      <th>station_id</th>\n",
       "      <th>train_id</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Returning</th>\n",
       "      <th>Dwell_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>Sebategna</td>\n",
       "      <td>NS23</td>\n",
       "      <td>20101</td>\n",
       "      <td>2025-07-24 06:08:09</td>\n",
       "      <td>2025-07-24 06:08:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abnet</td>\n",
       "      <td>NS22</td>\n",
       "      <td>20101</td>\n",
       "      <td>2025-07-24 06:10:11</td>\n",
       "      <td>2025-07-24 06:10:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Darmar T22010</td>\n",
       "      <td>NS21</td>\n",
       "      <td>20101</td>\n",
       "      <td>2025-07-24 06:12:52</td>\n",
       "      <td>2025-07-24 06:13:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>Sebategna</td>\n",
       "      <td>NS23</td>\n",
       "      <td>20201</td>\n",
       "      <td>2025-07-24 06:23:09</td>\n",
       "      <td>2025-07-24 06:23:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Abnet</td>\n",
       "      <td>NS22</td>\n",
       "      <td>20201</td>\n",
       "      <td>2025-07-24 06:25:11</td>\n",
       "      <td>2025-07-24 06:25:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>Meshoulekya</td>\n",
       "      <td>NS15</td>\n",
       "      <td>20101</td>\n",
       "      <td>2025-07-24 06:27:13</td>\n",
       "      <td>2025-07-24 06:27:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Darmar T22010</td>\n",
       "      <td>NS21</td>\n",
       "      <td>20201</td>\n",
       "      <td>2025-07-24 06:27:52</td>\n",
       "      <td>2025-07-24 06:28:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>Riche</td>\n",
       "      <td>NS14</td>\n",
       "      <td>20101</td>\n",
       "      <td>2025-07-24 06:28:52</td>\n",
       "      <td>2025-07-24 06:29:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>Temenja Yazh</td>\n",
       "      <td>NS13</td>\n",
       "      <td>20101</td>\n",
       "      <td>2025-07-24 06:30:42</td>\n",
       "      <td>2025-07-24 06:31:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>Lancha</td>\n",
       "      <td>NS12</td>\n",
       "      <td>20101</td>\n",
       "      <td>2025-07-24 06:32:38</td>\n",
       "      <td>2025-07-24 06:33:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>Sebategna</td>\n",
       "      <td>NS23</td>\n",
       "      <td>20301</td>\n",
       "      <td>2025-07-24 06:38:09</td>\n",
       "      <td>2025-07-24 06:38:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Abnet</td>\n",
       "      <td>NS22</td>\n",
       "      <td>20301</td>\n",
       "      <td>2025-07-24 06:40:11</td>\n",
       "      <td>2025-07-24 06:40:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>Meshoulekya</td>\n",
       "      <td>NS15</td>\n",
       "      <td>20201</td>\n",
       "      <td>2025-07-24 06:42:13</td>\n",
       "      <td>2025-07-24 06:42:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>Darmar T22010</td>\n",
       "      <td>NS21</td>\n",
       "      <td>20301</td>\n",
       "      <td>2025-07-24 06:42:52</td>\n",
       "      <td>2025-07-24 06:43:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>Saris</td>\n",
       "      <td>NS8</td>\n",
       "      <td>20101</td>\n",
       "      <td>2025-07-24 06:42:56</td>\n",
       "      <td>2025-07-24 06:43:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>Riche</td>\n",
       "      <td>NS14</td>\n",
       "      <td>20201</td>\n",
       "      <td>2025-07-24 06:43:52</td>\n",
       "      <td>2025-07-24 06:44:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>Temenja Yazh</td>\n",
       "      <td>NS13</td>\n",
       "      <td>20201</td>\n",
       "      <td>2025-07-24 06:45:42</td>\n",
       "      <td>2025-07-24 06:46:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Abo</td>\n",
       "      <td>NS7</td>\n",
       "      <td>20101</td>\n",
       "      <td>2025-07-24 06:45:45</td>\n",
       "      <td>2025-07-24 06:46:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>Lancha</td>\n",
       "      <td>NS12</td>\n",
       "      <td>20201</td>\n",
       "      <td>2025-07-24 06:47:38</td>\n",
       "      <td>2025-07-24 06:48:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>Sebategna</td>\n",
       "      <td>NS23</td>\n",
       "      <td>20401</td>\n",
       "      <td>2025-07-24 06:53:09</td>\n",
       "      <td>2025-07-24 06:53:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Abnet</td>\n",
       "      <td>NS22</td>\n",
       "      <td>20401</td>\n",
       "      <td>2025-07-24 06:55:11</td>\n",
       "      <td>2025-07-24 06:55:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>Meshoulekya</td>\n",
       "      <td>NS15</td>\n",
       "      <td>20301</td>\n",
       "      <td>2025-07-24 06:57:13</td>\n",
       "      <td>2025-07-24 06:57:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Darmar T22010</td>\n",
       "      <td>NS21</td>\n",
       "      <td>20401</td>\n",
       "      <td>2025-07-24 06:57:52</td>\n",
       "      <td>2025-07-24 06:58:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>Saris</td>\n",
       "      <td>NS8</td>\n",
       "      <td>20201</td>\n",
       "      <td>2025-07-24 06:57:56</td>\n",
       "      <td>2025-07-24 06:58:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>Riche</td>\n",
       "      <td>NS14</td>\n",
       "      <td>20301</td>\n",
       "      <td>2025-07-24 06:58:52</td>\n",
       "      <td>2025-07-24 06:59:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>Temenja Yazh</td>\n",
       "      <td>NS13</td>\n",
       "      <td>20301</td>\n",
       "      <td>2025-07-24 07:00:42</td>\n",
       "      <td>2025-07-24 07:01:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Abo</td>\n",
       "      <td>NS7</td>\n",
       "      <td>20201</td>\n",
       "      <td>2025-07-24 07:00:45</td>\n",
       "      <td>2025-07-24 07:01:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Lancha</td>\n",
       "      <td>NS12</td>\n",
       "      <td>20301</td>\n",
       "      <td>2025-07-24 07:02:38</td>\n",
       "      <td>2025-07-24 07:03:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Meshoulekya</td>\n",
       "      <td>NS15</td>\n",
       "      <td>20401</td>\n",
       "      <td>2025-07-24 07:12:13</td>\n",
       "      <td>2025-07-24 07:12:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>Saris</td>\n",
       "      <td>NS8</td>\n",
       "      <td>20301</td>\n",
       "      <td>2025-07-24 07:12:56</td>\n",
       "      <td>2025-07-24 07:13:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "arrival_departure       Stations station_id train_id             Arrival  \\\n",
       "1285                   Sebategna       NS23    20101 2025-07-24 06:08:09   \n",
       "0                          Abnet       NS22    20101 2025-07-24 06:10:11   \n",
       "340                Darmar T22010       NS21    20101 2025-07-24 06:12:52   \n",
       "1293                   Sebategna       NS23    20201 2025-07-24 06:23:09   \n",
       "8                          Abnet       NS22    20201 2025-07-24 06:25:11   \n",
       "877                  Meshoulekya       NS15    20101 2025-07-24 06:27:13   \n",
       "348                Darmar T22010       NS21    20201 2025-07-24 06:27:52   \n",
       "1149                       Riche       NS14    20101 2025-07-24 06:28:52   \n",
       "1557                Temenja Yazh       NS13    20101 2025-07-24 06:30:42   \n",
       "605                       Lancha       NS12    20101 2025-07-24 06:32:38   \n",
       "1301                   Sebategna       NS23    20301 2025-07-24 06:38:09   \n",
       "16                         Abnet       NS22    20301 2025-07-24 06:40:11   \n",
       "885                  Meshoulekya       NS15    20201 2025-07-24 06:42:13   \n",
       "356                Darmar T22010       NS21    20301 2025-07-24 06:42:52   \n",
       "1217                       Saris        NS8    20101 2025-07-24 06:42:56   \n",
       "1157                       Riche       NS14    20201 2025-07-24 06:43:52   \n",
       "1565                Temenja Yazh       NS13    20201 2025-07-24 06:45:42   \n",
       "68                           Abo        NS7    20101 2025-07-24 06:45:45   \n",
       "613                       Lancha       NS12    20201 2025-07-24 06:47:38   \n",
       "1309                   Sebategna       NS23    20401 2025-07-24 06:53:09   \n",
       "24                         Abnet       NS22    20401 2025-07-24 06:55:11   \n",
       "893                  Meshoulekya       NS15    20301 2025-07-24 06:57:13   \n",
       "364                Darmar T22010       NS21    20401 2025-07-24 06:57:52   \n",
       "1225                       Saris        NS8    20201 2025-07-24 06:57:56   \n",
       "1165                       Riche       NS14    20301 2025-07-24 06:58:52   \n",
       "1573                Temenja Yazh       NS13    20301 2025-07-24 07:00:42   \n",
       "76                           Abo        NS7    20201 2025-07-24 07:00:45   \n",
       "621                       Lancha       NS12    20301 2025-07-24 07:02:38   \n",
       "901                  Meshoulekya       NS15    20401 2025-07-24 07:12:13   \n",
       "1233                       Saris        NS8    20301 2025-07-24 07:12:56   \n",
       "\n",
       "arrival_departure           Departure Returning       Dwell_Time  \n",
       "1285              2025-07-24 06:08:34        NaN 0 days 00:00:25  \n",
       "0                 2025-07-24 06:10:36        NaN 0 days 00:00:25  \n",
       "340               2025-07-24 06:13:17        NaN 0 days 00:00:25  \n",
       "1293              2025-07-24 06:23:34        NaN 0 days 00:00:25  \n",
       "8                 2025-07-24 06:25:36        NaN 0 days 00:00:25  \n",
       "877               2025-07-24 06:27:38        NaN 0 days 00:00:25  \n",
       "348               2025-07-24 06:28:17        NaN 0 days 00:00:25  \n",
       "1149              2025-07-24 06:29:17        NaN 0 days 00:00:25  \n",
       "1557              2025-07-24 06:31:07        NaN 0 days 00:00:25  \n",
       "605               2025-07-24 06:33:03        NaN 0 days 00:00:25  \n",
       "1301              2025-07-24 06:38:34        NaN 0 days 00:00:25  \n",
       "16                2025-07-24 06:40:36        NaN 0 days 00:00:25  \n",
       "885               2025-07-24 06:42:38        NaN 0 days 00:00:25  \n",
       "356               2025-07-24 06:43:17        NaN 0 days 00:00:25  \n",
       "1217              2025-07-24 06:43:21        NaN 0 days 00:00:25  \n",
       "1157              2025-07-24 06:44:17        NaN 0 days 00:00:25  \n",
       "1565              2025-07-24 06:46:07        NaN 0 days 00:00:25  \n",
       "68                2025-07-24 06:46:10        NaN 0 days 00:00:25  \n",
       "613               2025-07-24 06:48:03        NaN 0 days 00:00:25  \n",
       "1309              2025-07-24 06:53:34        NaN 0 days 00:00:25  \n",
       "24                2025-07-24 06:55:36        NaN 0 days 00:00:25  \n",
       "893               2025-07-24 06:57:38        NaN 0 days 00:00:25  \n",
       "364               2025-07-24 06:58:17        NaN 0 days 00:00:25  \n",
       "1225              2025-07-24 06:58:21        NaN 0 days 00:00:25  \n",
       "1165              2025-07-24 06:59:17        NaN 0 days 00:00:25  \n",
       "1573              2025-07-24 07:01:07        NaN 0 days 00:00:25  \n",
       "76                2025-07-24 07:01:10        NaN 0 days 00:00:25  \n",
       "621               2025-07-24 07:03:03        NaN 0 days 00:00:25  \n",
       "901               2025-07-24 07:12:38        NaN 0 days 00:00:25  \n",
       "1233              2025-07-24 07:13:21        NaN 0 days 00:00:25  "
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1351f31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1625 entries, 1285 to 1624\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype          \n",
      "---  ------      --------------  -----          \n",
      " 0   Stations    1625 non-null   object         \n",
      " 1   station_id  1625 non-null   object         \n",
      " 2   train_id    1625 non-null   object         \n",
      " 3   Arrival     1474 non-null   datetime64[ns] \n",
      " 4   Departure   1474 non-null   datetime64[ns] \n",
      " 5   Returning   129 non-null    object         \n",
      " 6   Dwell_Time  1474 non-null   timedelta64[ns]\n",
      "dtypes: datetime64[ns](2), object(4), timedelta64[ns](1)\n",
      "memory usage: 101.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_pivot.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b81cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "counts = df_pivot.groupby('Stations').size()\n",
    "print(counts[counts <= 1])  # stations with 1 or 0 records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88889f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save df_privot as csv\n",
    "df_pivot.to_csv('../data/processed/NS_time_table_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87330ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Stations    Avg_Gap  Min_Gap  Max_Gap   Gap_Std\n",
      "0                      Abnet  14.560606      6.0     21.0  3.059054\n",
      "1                        Abo  14.560606      6.0     21.0  3.059054\n",
      "2                 Adey Ababa  14.560606      6.0     21.0  3.059054\n",
      "3             Atikilt Tera    14.560606      6.0     21.0  3.059054\n",
      "4               Autobus Tera  14.560606      6.0     21.0  3.059054\n",
      "5              Darmar T22010  14.560606      6.0     21.0  3.059054\n",
      "6              Gojam Berenda  14.560606      6.0     21.0  3.059054\n",
      "7              Kality T20619  14.560606      6.0     21.0  3.059054\n",
      "8                     Lancha  14.560606      6.0     21.0  3.059054\n",
      "9                     Leghar  14.560606      6.0     21.0  3.059054\n",
      "10  Menilik II Square T22705  14.560606      6.0     21.0  3.059054\n",
      "11               Meshoulekya  14.560606      6.0     21.0  3.059054\n",
      "12                    Mexico  14.560606      6.0     21.0  3.059054\n",
      "13              Nefas Silk 1  14.560606      6.0     21.0  3.059054\n",
      "14              Nefas Silk 2  14.560606      6.0     21.0  3.059054\n",
      "15                     Riche  14.560606      6.0     21.0  3.059054\n",
      "16                     Saris  14.560606      6.0     21.0  3.059054\n",
      "17                 Sebategna  14.560606      6.0     21.0  3.059054\n",
      "18                 St.Lideta  14.560606      6.0     21.0  3.059054\n",
      "19                   Stadium  14.560606      6.0     21.0  3.059054\n",
      "20                  Tegbared  14.560606      6.0     21.0  3.059054\n",
      "21              Temenja Yazh  14.560606      6.0     21.0  3.059054\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Assuming your data is loaded as `df` with columns: Stations, Arrival, Departure, etc.\n",
    "# Example structure:\n",
    "# df = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "\n",
    "# Sort by Stations and Arrival Time\n",
    "df_sorted = df_pivot.sort_values(['Stations', 'Arrival'])\n",
    "\n",
    "# Calculate Inter-Arrival Gaps (time between consecutive trains at the same station)\n",
    "df_sorted['Next_Arrival'] = df_sorted.groupby('Stations')['Arrival'].shift(-1)\n",
    "df_sorted['Arrival_Gap'] = (df_sorted['Next_Arrival'] - df_sorted['Arrival']).dt.total_seconds() / 60  # in minutes\n",
    "\n",
    "# Drop NaN (last train at each station has no \"next arrival\")\n",
    "df_gaps = df_sorted.dropna(subset=['Arrival_Gap'])\n",
    "\n",
    "# Aggregate by Stations\n",
    "station_stats = df_gaps.groupby('Stations')['Arrival_Gap'].agg(\n",
    "    Avg_Gap='mean',\n",
    "    Min_Gap='min',  # Busiest station (shortest gap)\n",
    "    Max_Gap='max',  # Least busy station (longest gap)\n",
    "    Gap_Std='std'   # Consistency of gaps\n",
    ").reset_index()\n",
    "\n",
    "# Sort by Avg_Gap to see busiest stations first\n",
    "station_stats = station_stats.sort_values('Avg_Gap')\n",
    "\n",
    "print(station_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
